{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f0bd04",
   "metadata": {},
   "source": [
    "Pre-processing YOLO + Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e59668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 55 parking_spots, 29.7ms\n",
      "Speed: 3.1ms preprocess, 29.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✅ Saved cropped image for spot 1: cropped_img\\roi_1.png\n",
      "✅ Saved cropped image for spot 2: cropped_img\\roi_2.png\n",
      "✅ Saved cropped image for spot 3: cropped_img\\roi_3.png\n",
      "✅ Saved cropped image for spot 4: cropped_img\\roi_4.png\n",
      "✅ Saved cropped image for spot 5: cropped_img\\roi_5.png\n",
      "✅ Saved cropped image for spot 6: cropped_img\\roi_6.png\n",
      "✅ Saved cropped image for spot 7: cropped_img\\roi_7.png\n",
      "✅ Saved cropped image for spot 8: cropped_img\\roi_8.png\n",
      "✅ Saved cropped image for spot 9: cropped_img\\roi_9.png\n",
      "✅ Saved cropped image for spot 10: cropped_img\\roi_10.png\n",
      "✅ Saved cropped image for spot 11: cropped_img\\roi_11.png\n",
      "✅ Saved cropped image for spot 12: cropped_img\\roi_12.png\n",
      "✅ Saved cropped image for spot 13: cropped_img\\roi_13.png\n",
      "✅ Saved cropped image for spot 14: cropped_img\\roi_14.png\n",
      "✅ Saved cropped image for spot 15: cropped_img\\roi_15.png\n",
      "✅ Saved cropped image for spot 16: cropped_img\\roi_16.png\n",
      "✅ Saved cropped image for spot 17: cropped_img\\roi_17.png\n",
      "✅ Saved cropped image for spot 18: cropped_img\\roi_18.png\n",
      "✅ Saved cropped image for spot 19: cropped_img\\roi_19.png\n",
      "✅ Saved cropped image for spot 20: cropped_img\\roi_20.png\n",
      "✅ Saved cropped image for spot 21: cropped_img\\roi_21.png\n",
      "✅ Saved cropped image for spot 22: cropped_img\\roi_22.png\n",
      "✅ Saved cropped image for spot 23: cropped_img\\roi_23.png\n",
      "✅ Saved cropped image for spot 24: cropped_img\\roi_24.png\n",
      "✅ Saved cropped image for spot 25: cropped_img\\roi_25.png\n",
      "✅ Saved cropped image for spot 26: cropped_img\\roi_26.png\n",
      "✅ Saved cropped image for spot 27: cropped_img\\roi_27.png\n",
      "✅ Saved cropped image for spot 28: cropped_img\\roi_28.png\n",
      "✅ Saved cropped image for spot 29: cropped_img\\roi_29.png\n",
      "✅ Saved cropped image for spot 30: cropped_img\\roi_30.png\n",
      "✅ Saved cropped image for spot 31: cropped_img\\roi_31.png\n",
      "✅ Saved cropped image for spot 32: cropped_img\\roi_32.png\n",
      "✅ Saved cropped image for spot 33: cropped_img\\roi_33.png\n",
      "✅ Saved cropped image for spot 34: cropped_img\\roi_34.png\n",
      "✅ Saved cropped image for spot 35: cropped_img\\roi_35.png\n",
      "✅ Saved cropped image for spot 36: cropped_img\\roi_36.png\n",
      "✅ Saved cropped image for spot 37: cropped_img\\roi_37.png\n",
      "✅ Saved cropped image for spot 38: cropped_img\\roi_38.png\n",
      "✅ Saved cropped image for spot 39: cropped_img\\roi_39.png\n",
      "✅ Saved cropped image for spot 40: cropped_img\\roi_40.png\n",
      "✅ Saved cropped image for spot 41: cropped_img\\roi_41.png\n",
      "✅ Saved cropped image for spot 42: cropped_img\\roi_42.png\n",
      "✅ Saved cropped image for spot 43: cropped_img\\roi_43.png\n",
      "✅ Saved cropped image for spot 44: cropped_img\\roi_44.png\n",
      "✅ Saved cropped image for spot 45: cropped_img\\roi_45.png\n",
      "✅ Saved cropped image for spot 46: cropped_img\\roi_46.png\n",
      "✅ Saved cropped image for spot 47: cropped_img\\roi_47.png\n",
      "✅ Saved cropped image for spot 48: cropped_img\\roi_48.png\n",
      "✅ Saved cropped image for spot 49: cropped_img\\roi_49.png\n",
      "✅ Saved cropped image for spot 50: cropped_img\\roi_50.png\n",
      "✅ Saved cropped image for spot 51: cropped_img\\roi_51.png\n",
      "✅ Saved cropped image for spot 52: cropped_img\\roi_52.png\n",
      "✅ Saved cropped image for spot 53: cropped_img\\roi_53.png\n",
      "✅ Saved cropped image for spot 54: cropped_img\\roi_54.png\n",
      "✅ Saved cropped image for spot 55: cropped_img\\roi_55.png\n",
      "✅ YOLO detection complete and saved.\n",
      "🗑️ Removed spot 24 at (117, 418)\n",
      "✅ Saved cropped image for spot 51: cropped_img\\roi_51.png\n",
      "🗑️ Removed spot 51 at (111, 483)\n",
      "✅ Saved cropped image for spot 50: cropped_img\\roi_50.png\n",
      "🗑️ Removed spot 50 at (112, 549)\n",
      "✅ Saved cropped image for spot 55: cropped_img\\roi_55.png\n",
      "🗑️ Removed spot 50 at (86, 486)\n",
      "🗑️ Removed spot 55 at (82, 548)\n",
      "✅ Saved cropped image for spot 50: cropped_img\\roi_50.png\n",
      "✅ Saved cropped image for spot 56: cropped_img\\roi_56.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdit Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m    110\u001b[0m     cv2\u001b[38;5;241m.\u001b[39msetMouseCallback(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdit Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, mouseclick)\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    115\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === Constants ===\n",
    "width = 130\n",
    "height = 65\n",
    "save_dir = 'cropped_img'\n",
    "image_path = 'car1.png'\n",
    "model_path = 'model/weights/best.pt'\n",
    "\n",
    "# Create cropped image save directory if it doesn't exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# === Load and Resize Image ===\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "base_image = image.copy()\n",
    "\n",
    "# === Load YOLOv8 Model ===\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# === Run YOLOv8 Inference ===\n",
    "results = model.predict(source=image, conf=0.25, show_labels=False, show_conf=True)\n",
    "detections = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "# === Build Detected Parking Spot List ===\n",
    "positionList = []\n",
    "for box in detections:\n",
    "    x1, y1, x2, y2 = box\n",
    "    x1, y1 = int(x1), int(y1)\n",
    "    positionList.append(((x1, y1), len(positionList) + 1))\n",
    "\n",
    "# === Save Cropped Images and Save Positions to Pickle ===\n",
    "def save_cropped_img(img, pos, number):\n",
    "    x, y = pos\n",
    "    cropped_img = img[y:y+height, x:x+width]\n",
    "    path = os.path.join(save_dir, f'roi_{number}.png')\n",
    "    cv2.imwrite(path, cropped_img)\n",
    "    print(f\"✅ Saved cropped image for spot {number}: {path}\")\n",
    "\n",
    "for pos, number in positionList:\n",
    "    save_cropped_img(image, pos, number)\n",
    "\n",
    "with open('carposition.pkl', 'wb') as f:\n",
    "    pickle.dump(positionList, f)\n",
    "\n",
    "print(\"✅ YOLO detection complete and saved.\")\n",
    "\n",
    "# === Manual Edit Mode ===\n",
    "selected_pos = None\n",
    "\n",
    "def mouseclick(event, x, y, flags, param):\n",
    "    global selected_pos, positionList\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selected_pos = (x, y)\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        for i, item in enumerate(positionList):\n",
    "            pos, number = item\n",
    "            x1, y1 = pos\n",
    "            if x1 < x < x1 + width and y1 < y < y1 + height:\n",
    "                print(f\"🗑️ Removed spot {number} at {pos}\")\n",
    "                positionList.pop(i)\n",
    "                with open('carposition.pkl', 'wb') as f:\n",
    "                    pickle.dump(positionList, f)\n",
    "                break\n",
    "\n",
    "def get_number_input(image, pos):\n",
    "    input_str = \"\"\n",
    "    while True:\n",
    "        temp_img = image.copy()\n",
    "        cv2.putText(temp_img, f\"Enter number: {input_str}\", (pos[0], pos[1] - 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Edit Mode\", temp_img)\n",
    "        key = cv2.waitKey(0)\n",
    "\n",
    "        if key in range(48, 58):  # 0–9\n",
    "            input_str += chr(key)\n",
    "        elif key == 8:  # Backspace\n",
    "            input_str = input_str[:-1]\n",
    "        elif key in [13, 10]:  # Enter\n",
    "            return int(input_str) if input_str.isdigit() else None\n",
    "        elif key == 27:  # ESC\n",
    "            return None\n",
    "\n",
    "# === Manual Editing Loop ===\n",
    "while True:\n",
    "    image = base_image.copy()\n",
    "\n",
    "    for pos, number in positionList:\n",
    "        x, y = pos\n",
    "        cv2.rectangle(image, (x, y), (x + width, y + height), (255, 0, 255), 2)\n",
    "        cv2.putText(image, str(number), (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "\n",
    "    if selected_pos:\n",
    "        new_number = get_number_input(image, selected_pos)\n",
    "        if new_number is not None:\n",
    "            positionList.append((selected_pos, new_number))\n",
    "            save_cropped_img(base_image, selected_pos, new_number)\n",
    "            with open('carposition.pkl', 'wb') as f:\n",
    "                pickle.dump(positionList, f)\n",
    "        selected_pos = None\n",
    "\n",
    "    cv2.imshow(\"Edit Mode\", image)\n",
    "    cv2.setMouseCallback(\"Edit Mode\", mouseclick)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
