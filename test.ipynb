{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a730793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "✅ Cleaned and saved corrected positionList.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 173\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    172\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m1280\u001b[39m, \u001b[38;5;241m720\u001b[39m))\n\u001b[1;32m--> 173\u001b[0m \u001b[43mcheckingCarParking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[1], line 87\u001b[0m, in \u001b[0;36mcheckingCarParking\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     85\u001b[0m x, y \u001b[38;5;241m=\u001b[39m pos\n\u001b[0;32m     86\u001b[0m cropped_img \u001b[38;5;241m=\u001b[39m img[y:y\u001b[38;5;241m+\u001b[39mheight, x:x\u001b[38;5;241m+\u001b[39mwidth]\n\u001b[1;32m---> 87\u001b[0m imgResized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m imgNormalized \u001b[38;5;241m=\u001b[39m imgResized \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     89\u001b[0m imgCrops\u001b[38;5;241m.\u001b[39mappend(imgNormalized)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# === GPU Setup ===\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available, running on CPU\")\n",
    "\n",
    "# === Load Model ===\n",
    "model = load_model(\"model_final.h5\")\n",
    "\n",
    "# === Class Labels ===\n",
    "class_dictionary = {0: 'no_car', 1: 'car', 2: 'wrong_parking'}\n",
    "\n",
    "# === Load Video ===\n",
    "video = cv2.VideoCapture(\"car_test_-car2.mp4\")\n",
    "\n",
    "# test function\n",
    "def alert_wrong_parking(spot_number):\n",
    "    print(spot_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Load and Fix carposition.pkl ===\n",
    "with open('carposition.pkl', 'rb') as f:\n",
    "    positionList = pickle.load(f)\n",
    "\n",
    "# Fix and enforce correct format\n",
    "fixed_list = []\n",
    "for i, item in enumerate(positionList):\n",
    "    if isinstance(item, tuple):\n",
    "        if len(item) == 2:\n",
    "            if isinstance(item[0], tuple) and isinstance(item[1], int):\n",
    "                # Already in ((x, y), spot_number) format\n",
    "                fixed_list.append(item)\n",
    "            elif isinstance(item[0], int) and isinstance(item[1], int):\n",
    "                # Old format: (x, y)\n",
    "                fixed_list.append(((item[0], item[1]), i + 1))\n",
    "            else:\n",
    "                print(f\"❌ Unrecognized format at index {i}: {item}\")\n",
    "        else:\n",
    "            print(f\"❌ Tuple of unexpected length at index {i}: {item}\")\n",
    "    else:\n",
    "        print(f\"❌ Not a tuple at index {i}: {item}\")\n",
    "\n",
    "positionList = fixed_list\n",
    "with open('carposition.pkl', 'wb') as f:\n",
    "    pickle.dump(positionList, f)\n",
    "print(\"✅ Cleaned and saved corrected positionList.\")\n",
    "\n",
    "# === Constants ===\n",
    "width, height = 130, 65\n",
    "confirmation_duration = 5  # seconds\n",
    "\n",
    "# === Trackers ===\n",
    "state_start_time = {}\n",
    "current_state = {}\n",
    "\n",
    "\n",
    "alerted_once = []\n",
    "\n",
    "# === Parking Check Function ===\n",
    "def checkingCarParking(img):\n",
    "    imgCrops = []\n",
    "    spot_info = []\n",
    "    spaceCounter = 0\n",
    "    wrongParkingCounter = 0\n",
    "\n",
    "    # Crop regions from image\n",
    "    for item in positionList:\n",
    "        pos, spot_number = item\n",
    "        x, y = pos\n",
    "        cropped_img = img[y:y+height, x:x+width]\n",
    "        imgResized = cv2.resize(cropped_img, (48, 48))\n",
    "        imgNormalized = imgResized / 255.0\n",
    "        imgCrops.append(imgNormalized)\n",
    "        spot_info.append({'position': pos, 'number': spot_number})\n",
    "\n",
    "    imgCrops = np.array(imgCrops)\n",
    "\n",
    "    # Predict\n",
    "    with tf.device('/GPU:0' if gpus else '/CPU:0'):\n",
    "        predictions = model.predict(imgCrops, verbose=0)\n",
    "\n",
    "    # Draw results\n",
    "    for i, spot in enumerate(spot_info):\n",
    "        pos = spot['position']\n",
    "        spot_number = spot['number']\n",
    "        x, y = pos\n",
    "        intId = np.argmax(predictions[i])\n",
    "        label = class_dictionary[intId]\n",
    "\n",
    "        # Update state and confirmation\n",
    "        if pos not in current_state:\n",
    "            current_state[pos] = label\n",
    "            state_start_time[pos] = time.time()\n",
    "\n",
    "        if label == current_state[pos]:\n",
    "            elapsed = time.time() - state_start_time[pos]\n",
    "            confirmed = elapsed >= confirmation_duration\n",
    "        else:\n",
    "            current_state[pos] = label\n",
    "            state_start_time[pos] = time.time()\n",
    "            confirmed = False\n",
    "\n",
    "        # Visual style\n",
    "        if label == 'no_car':\n",
    "            color = (0, 255, 0) if confirmed else (150, 255, 150)\n",
    "            thickness = 5\n",
    "            textColor = (0, 0, 0)\n",
    "            if confirmed:\n",
    "                spaceCounter += 1\n",
    "                if spot_number in alerted_once:\n",
    "                    alerted_once.remove(spot_number)\n",
    "        elif label == 'wrong_parking':\n",
    "            color = (255, 255, 0) if confirmed else (255, 255, 150)\n",
    "            thickness = 2\n",
    "            textColor = (255, 255, 255)\n",
    "            if confirmed:\n",
    "                wrongParkingCounter += 1\n",
    "                if spot_number not in alerted_once:\n",
    "                    alert_wrong_parking(spot_number)\n",
    "                    alerted_once.append(spot_number)\n",
    "        else:\n",
    "            color = (0, 0, 255) if confirmed else (150, 150, 255)\n",
    "            thickness = 2\n",
    "            textColor = (255, 255, 255)\n",
    "            if spot_number in alerted_once:\n",
    "                alerted_once.remove(spot_number)\n",
    "\n",
    "        # Draw box\n",
    "        cv2.rectangle(img, pos, (pos[0]+width, pos[1]+height), color, thickness)\n",
    "\n",
    "        # Draw label box and text\n",
    "        font_scale = 0.5\n",
    "        text_thickness = 1\n",
    "        textSize = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_thickness)[0]\n",
    "        textX = x\n",
    "        textY = y + height - 5\n",
    "        cv2.rectangle(img, (textX, textY - textSize[1] - 5), (textX + textSize[0] + 6, textY + 2), color, -1)\n",
    "        cv2.putText(img, label, (textX + 3, textY - 3), cv2.FONT_HERSHEY_SIMPLEX, font_scale, textColor, text_thickness)\n",
    "\n",
    "        # Draw spot number\n",
    "        cv2.putText(img, str(spot_number), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw summary\n",
    "    cv2.putText(img, f'Space Count: {spaceCounter}', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(img, f'Wrong Parking Count: {wrongParkingCounter}', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "# === Main Loop ===\n",
    "while True:\n",
    "    if video.get(cv2.CAP_PROP_POS_FRAMES) == video.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    ret, image = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    image = cv2.resize(image, (1280, 720))\n",
    "    checkingCarParking(image)\n",
    "    cv2.imshow(\"Image\", image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659714c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121ae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c940d3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_model = YOLO('parking_spot_detection/yolov8_parking_model/weights/best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bc5c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics.yolo.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DetectionModel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Import the Conv class from the new location\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01myolo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv \u001b[38;5;28;01mas\u001b[39;00m RealConv\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Monkey-patch its module attribute to match the old global name expected by the checkpoint\u001b[39;00m\n\u001b[0;32m     17\u001b[0m RealConv\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124multralytics.nn.modules.conv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics.yolo.models'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response, jsonify\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.modules.container as container_module  # Already added before\n",
    "from send_alert import alert_wrong_parking\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from ultralytics.nn.modules.conv import Conv  # Import Conv\n",
    "\n",
    "# === Allow YOLO Model Classes for Safe Loading (PyTorch >= 2.6) ===\n",
    "torch.serialization.add_safe_globals([DetectionModel])\n",
    "torch.serialization.add_safe_globals([container_module.Sequential])\n",
    "torch.serialization.add_safe_globals([Conv])  # Allow Conv class\n",
    "\n",
    "# === Initialize Flask App ===\n",
    "app = Flask(__name__)\n",
    "\n",
    "# === GPU Configuration for TensorFlow ===\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available, running on CPU\")\n",
    "\n",
    "# === Load Models ===\n",
    "classifier_model = load_model('model_final.h5')\n",
    "yolo_model = YOLO('parking_spot_detection/yolov8_parking_model/weights/best.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Class Mapping ===\n",
    "class_dictionary = {0: 'no_car', 1: 'car', 2: 'wrong_parking'}\n",
    "\n",
    "# === Parameters and State Tracking ===\n",
    "confirmation_duration = 5\n",
    "state_start_time = {}\n",
    "current_state = {}\n",
    "alerted_once = []\n",
    "\n",
    "# === Load Video ===\n",
    "cap = cv2.VideoCapture('car_test_-car2.mp4')\n",
    "\n",
    "# === Parking Spot Detection and Classification ===\n",
    "def checkParkingSpace(img):\n",
    "    imgCrops = []\n",
    "    spot_info = []\n",
    "    spaceCounter = 0\n",
    "    wrongParkingCounter = 0\n",
    "\n",
    "    results = yolo_model.predict(img, conf=0.4, show_labels=False, show_conf=False, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cropped_img = img[y1:y2, x1:x2]\n",
    "        if cropped_img.shape[0] == 0 or cropped_img.shape[1] == 0:\n",
    "            continue\n",
    "        imgResized = cv2.resize(cropped_img, (48, 48))\n",
    "        imgNormalized = imgResized / 255.0\n",
    "        imgCrops.append(imgNormalized)\n",
    "        spot_info.append({'bbox': box, 'number': i + 1})\n",
    "\n",
    "    if not imgCrops:\n",
    "        return img, 0, 0, 0\n",
    "\n",
    "    imgCrops = np.array(imgCrops)\n",
    "\n",
    "    with tf.device('/GPU:0' if gpus else '/CPU:0'):\n",
    "        predictions = classifier_model.predict(imgCrops, verbose=0)\n",
    "\n",
    "    for i, spot in enumerate(spot_info):\n",
    "        x1, y1, x2, y2 = spot['bbox']\n",
    "        spot_number = spot['number']\n",
    "        intId = np.argmax(predictions[i])\n",
    "        label = class_dictionary[intId]\n",
    "\n",
    "        pos_key = (x1, y1, x2, y2)\n",
    "        if pos_key not in current_state:\n",
    "            current_state[pos_key] = label\n",
    "            state_start_time[pos_key] = time.time()\n",
    "\n",
    "        if label == current_state[pos_key]:\n",
    "            elapsed = time.time() - state_start_time[pos_key]\n",
    "            confirmed = elapsed >= confirmation_duration\n",
    "        else:\n",
    "            current_state[pos_key] = label\n",
    "            state_start_time[pos_key] = time.time()\n",
    "            confirmed = False\n",
    "\n",
    "        if label == 'no_car':\n",
    "            color = (0, 255, 0) if confirmed else (150, 255, 150)\n",
    "            thickness = 5\n",
    "            textColor = (0, 0, 0)\n",
    "            if confirmed:\n",
    "                spaceCounter += 1\n",
    "                if spot_number in alerted_once:\n",
    "                    alerted_once.remove(spot_number)\n",
    "        elif label == 'wrong_parking':\n",
    "            color = (255, 255, 0) if confirmed else (255, 255, 150)\n",
    "            thickness = 2\n",
    "            textColor = (255, 255, 255)\n",
    "            if confirmed:\n",
    "                wrongParkingCounter += 1\n",
    "                if spot_number not in alerted_once:\n",
    "                    alert_wrong_parking(spot_number)\n",
    "                    alerted_once.append(spot_number)\n",
    "        else:\n",
    "            color = (0, 0, 255) if confirmed else (150, 150, 255)\n",
    "            thickness = 2\n",
    "            textColor = (255, 255, 255)\n",
    "            if spot_number in alerted_once:\n",
    "                alerted_once.remove(spot_number)\n",
    "\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "        cv2.putText(img, label, (x1 + 3, y2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, textColor, 1)\n",
    "        cv2.putText(img, str(spot_number), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    totalSpaces = len(spot_info)\n",
    "    occupied_spaces = totalSpaces - spaceCounter - wrongParkingCounter\n",
    "\n",
    "    cv2.putText(img, f'Space Count: {spaceCounter}', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(img, f'Wrong Parking Count: {wrongParkingCounter}', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    return img, spaceCounter, wrongParkingCounter, occupied_spaces\n",
    "\n",
    "# === Frame Generator for MJPEG Streaming ===\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        img = cv2.resize(img, (1280, 720))\n",
    "        img, free_spaces, wrong_parking_spaces, occupied_spaces = checkParkingSpace(img)\n",
    "\n",
    "        ret, buffer = cv2.imencode('.jpg', img)\n",
    "        img = buffer.tobytes()\n",
    "\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + img + b'\\r\\n')\n",
    "\n",
    "# === Flask Routes ===\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/space_count')\n",
    "def space_count():\n",
    "    success, img = cap.read()\n",
    "    if success:\n",
    "        img = cv2.resize(img, (1280, 720))\n",
    "        _, free_spaces, wrong_parking_spaces, occupied_spaces = checkParkingSpace(img)\n",
    "        return jsonify(free=free_spaces, wrong=wrong_parking_spaces, occupied=occupied_spaces)\n",
    "    return jsonify(free=0, wrong=0, occupied=0)\n",
    "\n",
    "# === Run Flask App ===\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fineTuning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
